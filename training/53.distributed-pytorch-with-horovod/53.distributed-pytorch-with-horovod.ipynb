{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Distributed Demo\n",
    "\n",
    "In this demo, we will run a sample PyTorch job using Horovod on a multi-node Batch AI cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure you go through the [00. Installation and Configuration](00.configuration.ipynb) Notebook first if you haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set experiment name and create project\n",
    "Choose a name for your run history container in the workspace, and create a folder for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "experiment_name = 'pytorch-dist-hvd'\n",
    "\n",
    "# project folder\n",
    "project_folder = './sample_projects/pytorch-dist-hvd'\n",
    "os.makedirs(project_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write demo PyTorch code\n",
    "\n",
    "We will use a distributed PyTorch implementation of the classic MNIST problem. The following cell writes the main implementation to the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {project_folder}/pytorch_horovod_mnist.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data.distributed\n",
    "import horovod.torch as hvd\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "hvd.init()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.cuda:\n",
    "    # Horovod: pin GPU to local rank.\n",
    "    torch.cuda.set_device(hvd.local_rank())\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_dataset = \\\n",
    "    datasets.MNIST('data-%d' % hvd.rank(), train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n",
    "\n",
    "test_dataset = \\\n",
    "    datasets.MNIST('data-%d' % hvd.rank(), train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n",
    "                                          sampler=test_sampler, **kwargs)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "if args.cuda:\n",
    "    # Move model to GPU.\n",
    "    model.cuda()\n",
    "\n",
    "# Horovod: broadcast parameters.\n",
    "hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
    "\n",
    "# Horovod: scale learning rate by the number of GPUs.\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr * hvd.size(),\n",
    "                      momentum=args.momentum)\n",
    "\n",
    "# Horovod: wrap optimizer with DistributedOptimizer.\n",
    "optimizer = hvd.DistributedOptimizer(\n",
    "    optimizer, named_parameters=model.named_parameters())\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_sampler.set_epoch(epoch)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_sampler),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def metric_average(val, name):\n",
    "    tensor = torch.FloatTensor([val])\n",
    "    avg_tensor = hvd.allreduce(tensor, name=name)\n",
    "    return avg_tensor[0]\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_accuracy = 0.\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n",
    "\n",
    "    test_loss /= len(test_sampler)\n",
    "    test_accuracy /= len(test_sampler)\n",
    "\n",
    "    test_loss = metric_average(test_loss, 'avg_loss')\n",
    "    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n",
    "\n",
    "    if hvd.rank() == 0:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "            test_loss, 100. * test_accuracy))\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Batch AI cluster\n",
    "\n",
    "To run this in a distributed context, we'll need a Batch AI cluster with at least two nodes.\n",
    "\n",
    "Here, we use exactly two CPU nodes, to conserve resources. If you want to try it with some other number or SKU, just change the relevant values in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "batchai_cluster_name='gpucluster'\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing cluster\n",
    "    compute_target = ComputeTarget(ws,batchai_cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except:\n",
    "    # Else, create new one\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\", # NC6 is GPU-enabled\n",
    "                                                                    #vm_priority = 'lowpriority', # optional\n",
    "                                                                    autoscale_enabled = True,\n",
    "                                                                    cluster_min_nodes = 0, \n",
    "                                                                    cluster_max_nodes = 4)\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    " # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job\n",
    "\n",
    "Now that we have a cluster ready to go, let's submit our job.\n",
    "\n",
    "We need to use a custom estimator here, and specify that we want the `pytorch`, `horovod` and `torchvision` packages installed to our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='pytorch_horovod_mnist.py',\n",
    "                    node_count=2,\n",
    "                    process_count_per_node=1,\n",
    "                    distributed_backend=\"mpi\",\n",
    "                    use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
